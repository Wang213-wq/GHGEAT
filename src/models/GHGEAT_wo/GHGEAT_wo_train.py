"""
GH-GNN without MTL训练
"""
import numpy as np
# Scientific computing
import pandas as pd
import sys  # 用于检测操作系统平台

# RDKiT
from rdkit import Chem

# Internal utilities
from scr.models.utilities_v2.mol2graph import get_dataloader_pairs_T, sys2graph, n_atom_features, n_bond_features
from scr.models.GH_pyGEAT_wo_architecture_0615_v0 import GHGEAT_wo, count_parameters
from scr.models.utilities_v2.Train_eval_T import MAE, R2
from scr.models.utilities_v2.save_info import save_train_traj

# External utilities
from tqdm import tqdm
#tqdm.pandas()
from collections import OrderedDict
import copy
import time
import os

# Pytorch
import torch
import torch.nn.functional as F
from torch.optim.lr_scheduler import ReduceLROnPlateau as reduce_lr
from torch.amp import GradScaler

# 注意：为了可重复性，cudnn.benchmark 和 cudnn.deterministic 不能同时为 True
# 在训练函数中会根据随机种子设置来决定使用哪个
torch.backends.cudnn.benchmark = True  # 默认使用benchmark以提高性能
if hasattr(torch.backends.cuda.matmul, "allow_tf32"):
    torch.backends.cuda.matmul.allow_tf32 = True
try:
    torch.set_float32_matmul_precision('medium')
except AttributeError:
    pass


def train_GNNGH_T(df, model_name, hyperparameters, resume=False, val_df=None):
    """
    训练GHGEAT单任务模型
    
    Parameters:
    -----------
    df : pd.DataFrame
        训练数据
    model_name : str
        模型名称
    hyperparameters : dict
        超参数字典
    resume : bool
        是否从检查点恢复训练（默认False）
    val_df : pd.DataFrame, optional
        验证集数据（如果提供，将在每个epoch评估验证集）
    """
    # 优化系统性能：设置进程优先级（减少夜间运行时因系统资源竞争导致的训练时间变长）
    try:
        import psutil
        current_process = psutil.Process(os.getpid())
        if sys.platform == 'win32':
            try:
                # Windows: 设置高优先级
                current_process.nice(psutil.HIGH_PRIORITY_CLASS)
            except (psutil.AccessDenied, AttributeError):
                # 如果无法设置，尝试使用Windows API
                try:
                    import ctypes
                    kernel32 = ctypes.windll.kernel32
                    # HIGH_PRIORITY_CLASS = 0x00000080
                    kernel32.SetPriorityClass(kernel32.GetCurrentProcess(), 0x00000080)
                except:
                    pass  # 如果都失败，静默继续
        else:
            try:
                current_process.nice(-10)  # 降低nice值（提高优先级）
            except (psutil.AccessDenied, AttributeError):
                pass
    except ImportError:
        # psutil未安装，尝试使用Windows API（仅Windows）
        if sys.platform == 'win32':
            try:
                import ctypes
                kernel32 = ctypes.windll.kernel32
                kernel32.SetPriorityClass(kernel32.GetCurrentProcess(), 0x00000080)
            except:
                pass
    
    # 设置随机种子以确保可重复性
    import random
    random_seed = 42
    random.seed(random_seed)
    np.random.seed(random_seed)
    torch.manual_seed(random_seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(random_seed)
        torch.cuda.manual_seed_all(random_seed)
        # 更偏向训练速度：允许cuDNN选择最快算法（牺牲一点严格可重复性）
        torch.backends.cudnn.deterministic = False
        torch.backends.cudnn.benchmark = True
    
    # 创建用于DataLoader的随机数生成器（确保数据shuffle的可重复性）
    generator = torch.Generator()
    generator.manual_seed(random_seed)
    
    path = os.getcwd()
    # 支持memory_size目录结构：如果model_name包含'/'，则按目录结构创建
    # 例如：EA_sensitivity_mem32/EA_sensitivity_hp_mem32_lr... -> ReLU/EA_sensitivity_mem32/EA_sensitivity_hp_mem32_lr...
    if '/' in model_name:
        # 包含目录结构，直接使用（使用os.path.join确保跨平台兼容）
        path = os.path.join(path, 'ReLU', model_name)
    else:
        # 不包含目录结构，使用原来的方式
        path = os.path.join(path, 'ReLU', model_name)
    
    # 使用os.makedirs创建所有必要的父目录（如果不存在）
    # exist_ok=True表示如果目录已存在不会报错
    os.makedirs(path, exist_ok=True)
    
    # 检查点文件路径（使用model_name的最后一部分作为文件名）
    model_name_basename = model_name.split('/')[-1] if '/' in model_name else model_name
    checkpoint_path = os.path.join(path, model_name_basename + '_checkpoint.pth')



    # Open report file (使用UTF-8编码以支持Unicode字符)
    report = open(os.path.join(path, 'Report_training_' + model_name_basename + '.txt'), 'w', encoding='utf-8')
    def print_report(string, file=report):
        print(string)
        file.write('\n' + string)

    print_report(' Report for ' + model_name)
    print_report('-'*50)
    print_report(f'Training data size: {len(df)}')
    if val_df is not None:
        print_report(f'Validation data size: {len(val_df)}')
        print_report('✓ 验证集已加载，将使用验证集进行评估和早停')
    
    # Build molecule from SMILES
    mol_column_solvent     = 'Molecule_Solvent'
    df[mol_column_solvent] = df['Solvent_SMILES'].apply(Chem.MolFromSmiles)

    mol_column_solute      = 'Molecule_Solute'
    df[mol_column_solute]  = df['Solute_SMILES'].apply(Chem.MolFromSmiles)
    
    train_index = df.index.tolist()
    
    target = 'log-gamma'
    #targets = ['K1','K2']
    # scaler = MinMaxScaler()
    # scaler = scaler.fit(df[target].to_numpy())
    
    graphs_solv, graphs_solu = 'g_solv', 'g_solu'
    df[graphs_solv], df[graphs_solu] = sys2graph(df, mol_column_solvent, mol_column_solute, target)
    
    # Hyperparameters（需要先提取batch_size用于创建数据加载器）
    hidden_dim  = hyperparameters['hidden_dim']
    lr          = hyperparameters['lr']
    n_epochs    = hyperparameters['n_epochs']
    batch_size  = hyperparameters['batch_size']
    early_stopping_patience = hyperparameters.get('early_stopping_patience', 20)
    # 验证集评估间隔（单位：epoch），默认每轮都评估
    eval_interval = hyperparameters.get('eval_interval', 1)
    # 单次搜索终止条件（用于敏感性分析）
    single_trial_epochs_threshold = hyperparameters.get('single_trial_epochs_threshold', None)  # 训练轮数阈值
    single_trial_mae_after_epochs_threshold = hyperparameters.get('single_trial_mae_after_epochs_threshold', None)  # 训练指定轮数后MAE阈值
    single_trial_start_mae_threshold = hyperparameters.get('single_trial_start_mae_threshold', None)  # 起始MAE阈值
    
    # 处理验证集数据（如果提供）
    val_loader = None
    if val_df is not None:
        val_df = val_df.copy()
        val_df[mol_column_solvent] = val_df['Solvent_SMILES'].apply(Chem.MolFromSmiles)
        val_df[mol_column_solute] = val_df['Solute_SMILES'].apply(Chem.MolFromSmiles)
        val_index = val_df.index.tolist()
        val_df[graphs_solv], val_df[graphs_solu] = sys2graph(val_df, mol_column_solvent, mol_column_solute, target)
        
        # 创建验证集数据加载器
        # 优化：使用优化的数据加载设置以加速验证集评估
        val_batch_size = hyperparameters.get('val_batch_size', batch_size)  # 验证集batch size与训练batch size保持一致
        val_num_workers = hyperparameters.get('val_num_workers', 2)  # 验证集数据加载进程数
        val_pin_memory = hyperparameters.get('val_pin_memory', True)  # 启用内存固定以加速GPU传输
        val_prefetch_factor = hyperparameters.get('val_prefetch_factor', 2)  # 验证集预取批次数量
        
        try:
            val_loader = get_dataloader_pairs_T(val_df,
                                              val_index,
                                              graphs_solv,
                                              graphs_solu,
                                              val_batch_size,  # 使用更大的batch size
                                              shuffle=False,  # 验证集不需要shuffle
                                              drop_last=False,  # 验证集保留所有数据
                                              generator=generator,
                                              num_workers=val_num_workers,  # 启用多进程数据加载
                                              pin_memory=val_pin_memory,  # 启用内存固定
                                              persistent_workers=(val_num_workers > 0),  # 保持worker进程存活
                                              prefetch_factor=val_prefetch_factor)  # 添加预取因子
            print_report(f'✓ 验证集数据加载器创建成功，验证集大小: {len(val_df)}, batch_size: {val_batch_size}, num_workers: {val_num_workers}')
        except Exception as e:
            print_report(f'⚠️ 警告: 创建验证集数据加载器失败: {e}')
            import traceback
            traceback.print_exc()
            print_report('将仅使用训练集进行评估')
            val_loader = None
    # use_external_attention = hyperparameters.get('use_external_attention', False)
    # attn_alpha = hyperparameters.get('attn_alpha', 0.5)
    # attention_memory_size = hyperparameters.get('attention_memory_size', 128)
    
    start       = time.time()
    last_pause_time = start  # 记录上次暂停的时间，用于计算是否达到4小时
    
    # Data loaders
    # 优化：为训练数据加载器添加多进程和内存固定等优化参数
    train_num_workers = hyperparameters.get('train_num_workers', 4)  # 训练数据加载进程数
    train_pin_memory = hyperparameters.get('train_pin_memory', True)  # 启用内存固定以加速GPU传输
    train_persistent_workers = hyperparameters.get('train_persistent_workers', True)  # 保持worker进程存活
    train_prefetch_factor = hyperparameters.get('train_prefetch_factor', 2)  # 预取批次数量，增加可提高GPU利用率
    train_loader = get_dataloader_pairs_T(df,
                                          train_index, 
                                          graphs_solv,
                                          graphs_solu,
                                          batch_size,
                                          shuffle=True, 
                                          drop_last=True,
                                          generator=generator,  # 使用固定种子的生成器确保shuffle可重复
                                          num_workers=train_num_workers,
                                          pin_memory=train_pin_memory,
                                          persistent_workers=train_persistent_workers,
                                          prefetch_factor=train_prefetch_factor)  # 添加预取因子
    
    # Model
    v_in = n_atom_features()
    e_in = n_bond_features()
    print("v_in:{}".format(v_in))
    print("e_in:{}".format(e_in))
    u_in = 3 # ap, bp, topopsa
    model = GHGEAT_wo(v_in, e_in, u_in, hidden_dim)
    # model = GHGEAT_wo(v_in, e_in, u_in, hidden_dim,
    #                  use_external_attention=use_external_attention,
    #                  attn_alpha=attn_alpha,
    #                  memory_size=attention_memory_size)
    # 智能选择GPU设备：使用GPU 0
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        print_report(f'检测到 {gpu_count} 个CUDA设备（PyTorch可用的NVIDIA GPU）')
        # 显示所有可用的GPU信息
        for i in range(gpu_count):
            gpu_name = torch.cuda.get_device_name(i)
            print_report(f'  GPU {i}: {gpu_name}')
        
        device = torch.device('cuda:0')
        device_index = 0
        print_report(f'使用 GPU 0 进行训练')
    else:
        device = torch.device('cpu')
        device_index = None
        print_report('CUDA不可用，使用 CPU 进行训练')
    
    model    = model.to(device)
    
    # 已取消torch.compile加速
    
    scaler = GradScaler('cuda', enabled=(device.type == 'cuda'))
    if device.type == 'cuda':
        device_name = torch.cuda.get_device_name(device_index)
        print_report(f'Using device: {device_name} (GPU {device_index})')
    else:
        device_name = 'CPU'
        print_report(f'Using device: {device_name}')
    
    print('Number of model parameters: ', count_parameters(model))
    
    # Optimizer
    # 使用标准AdamW优化器（已取消fused优化）
    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)
    
    scheduler = reduce_lr(optimizer, mode='min', factor=0.8, patience=3, min_lr=1e-7)

    # To save trajectory
    mae_train = []
    r2_train = []
    train_loss = []
    mae_valid = []  # 验证集MAE
    r2_valid = []   # 验证集R²
    best_MAE = np.inf
    best_model = None
    epochs_no_improve = 0
    start_epoch = 0
    use_validation = val_loader is not None  # 是否使用验证集
    
    # 调试信息：确认验证集状态
    if val_df is not None:
        print_report(f'调试: val_df不为None, val_loader状态: {val_loader is not None}, use_validation: {use_validation}')
    else:
        print_report('调试: val_df为None，将仅使用训练集')
    
    # 尝试从检查点恢复训练
    if resume and os.path.exists(checkpoint_path):
        try:
            print_report(f'检测到检查点文件: {checkpoint_path}')
            print_report('正在加载检查点...')
            checkpoint = torch.load(checkpoint_path, map_location=device)
            
            # 加载模型状态（已取消torch.compile相关处理）
            model.load_state_dict(checkpoint['model_state_dict'])
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
            if 'scaler_state_dict' in checkpoint:
                scaler.load_state_dict(checkpoint['scaler_state_dict'])
            
            # 恢复训练状态
            start_epoch = checkpoint['epoch'] + 1
            
            # 尝试从检查点加载训练历史，如果没有则从CSV文件读取
            mae_train = checkpoint.get('mae_train', None)
            r2_train = checkpoint.get('r2_train', None)
            train_loss = checkpoint.get('train_loss', None)
            mae_valid = checkpoint.get('mae_valid', None)
            r2_valid = checkpoint.get('r2_valid', None)
            
            # 如果检查点中没有训练历史，尝试从CSV文件读取
            if mae_train is None:
                traj_path = os.path.join(path, 'Training.csv')
                if os.path.exists(traj_path):
                    try:
                        traj_df = pd.read_csv(traj_path)
                        if 'MAE_Train' in traj_df.columns:
                            mae_train = traj_df['MAE_Train'].tolist()
                        else:
                            mae_train = []
                        if 'R2_Train' in traj_df.columns:
                            r2_train = traj_df['R2_Train'].tolist()
                        else:
                            r2_train = []
                        if 'Train_loss' in traj_df.columns:
                            train_loss = traj_df['Train_loss'].tolist()
                        else:
                            train_loss = []
                        if use_validation:
                            if 'MAE_Valid' in traj_df.columns:
                                mae_valid = traj_df['MAE_Valid'].tolist()
                            else:
                                mae_valid = []
                            if 'R2_Valid' in traj_df.columns:
                                r2_valid = traj_df['R2_Valid'].tolist()
                            else:
                                r2_valid = []
                        print_report(f'从CSV文件恢复训练历史: {len(mae_train)} 个epoch的记录')
                    except Exception as e:
                        print_report(f'警告: 从CSV文件读取训练历史失败: {e}，将初始化为空列表')
                        mae_train = []
                        r2_train = []
                        train_loss = []
                        mae_valid = []
                        r2_valid = []
                else:
                    # 如果CSV文件也不存在，初始化为空列表
                    mae_train = []
                    r2_train = []
                    train_loss = []
                    mae_valid = []
                    r2_valid = []
            
            # 确保验证集指标长度与训练集指标长度匹配（如果使用验证集）
            if use_validation:
                train_len = len(mae_train)
                val_len = len(mae_valid) if mae_valid is not None else 0
                if val_len != train_len:
                    # 静默重置验证集指标，避免重复警告输出
                    mae_valid = []
                    r2_valid = []
            
            best_MAE = checkpoint.get('best_MAE', np.inf)
            best_model = checkpoint.get('best_model_state_dict', None)
            epochs_no_improve = checkpoint.get('epochs_no_improve', 0)
            
            print_report(f'成功加载检查点！')
            print_report(f'将从第 {start_epoch + 1} 轮继续训练（共 {n_epochs} 轮）')
            print_report(f'已训练轮数: {len(mae_train)}')
            if len(mae_train) > 0:
                print_report(f'当前最佳MAE: {best_MAE:.6f}')
        except Exception as e:
            print_report(f'警告: 加载检查点失败: {e}')
            print_report('将从第1轮开始训练')
            start_epoch = 0
    elif resume:
        print_report(f'未找到检查点文件: {checkpoint_path}')
        print_report('将从第1轮开始训练')
    else:
        print_report('断点续训已禁用，将从第1轮开始训练')

    # 已取消torch.compile加速（避免Triton依赖问题）

    # GPU预热：执行一次完整的dummy forward/backward pass以减少第1轮训练时间
    # 这可以预编译CUDA kernels并初始化GPU内存分配
    if start_epoch == 0 and device.type == 'cuda' and len(train_loader) > 0:
        print_report('执行GPU预热（dummy forward/backward pass）以减少第1轮训练时间...')
        try:
            model.train()
            # 获取第一个batch
            first_batch = next(iter(train_loader))
            
            # 准备数据
            if len(first_batch) == 3:
                batch_solvent, batch_solute, T = first_batch
                T = T.to(device, non_blocking=True)
                has_temperature = True
            elif len(first_batch) == 2:
                batch_solvent, batch_solute = first_batch
                has_temperature = False
            else:
                raise ValueError(f"Unexpected batch size {len(first_batch)}")
            
            batch_solvent = batch_solvent.to(device, non_blocking=True)
            batch_solute = batch_solute.to(device, non_blocking=True)
            
            # Dummy forward pass
            optimizer.zero_grad(set_to_none=True)
            with torch.autocast(device_type=device.type, enabled=(device.type == 'cuda')):
                if has_temperature:
                    pred = model(batch_solvent, batch_solute, T)
                else:
                    pred = model(batch_solvent, batch_solute)
                prediction = pred.to(torch.float32)
                real = batch_solvent.y.to(torch.float32).reshape(prediction.shape)
                loss = F.mse_loss(prediction, real)
            
            # Dummy backward pass
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            
            # 同步确保操作完成
            torch.cuda.synchronize()
            # 清理GPU缓存
            torch.cuda.empty_cache()
            
            print_report('✓ GPU预热完成')
        except Exception as e:
            print_report(f'⚠️ GPU预热过程中出现错误: {e}，将继续正常训练')

    # Training loop
    for epoch in range(start_epoch, n_epochs):
        epoch_start = time.time()
        train_start = time.time()
        model.train()
        loss_sum = 0.0
        total_graphs = 0
        y_true_batches = []
        y_pred_batches = []
        
        for batch_data in train_loader:
            if len(batch_data) == 3:
                batch_solvent, batch_solute, T = batch_data
                T = T.to(device, non_blocking=True)  # 使用非阻塞传输，提高GPU利用率稳定性
                has_temperature = True
            elif len(batch_data) == 2:
                batch_solvent, batch_solute = batch_data
                has_temperature = False
            else:
                raise ValueError(f"Unexpected batch size {len(batch_data)}")
            
            batch_solvent = batch_solvent.to(device, non_blocking=True)  # 使用非阻塞传输
            batch_solute = batch_solute.to(device, non_blocking=True)  # 使用非阻塞传输
            optimizer.zero_grad(set_to_none=True)
            
            with torch.autocast(device_type=device.type, enabled=(device.type == 'cuda')):
                if has_temperature:
                    pred = model(batch_solvent, batch_solute, T)
                else:
                    pred = model(batch_solvent, batch_solute)
                prediction = pred.to(torch.float32)
                real = batch_solvent.y.to(torch.float32).reshape(prediction.shape)
                loss = F.mse_loss(prediction, real)
            
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            
            num_graphs = batch_solvent.num_graphs
            loss_sum += loss.item() * num_graphs
            total_graphs += num_graphs
            # 注意：cpu()方法不支持non_blocking参数，只能用于to()或cuda()方法
            # 从GPU传输到CPU时，数据已经在GPU上计算完成，直接传输即可
            y_true_batches.append(real.detach().cpu())
            y_pred_batches.append(prediction.detach().cpu())
        
        epoch_loss = loss_sum / total_graphs
        y_true = torch.cat(y_true_batches, dim=0).numpy()
        y_pred = torch.cat(y_pred_batches, dim=0).numpy()
        pred_dict = {"y_true": y_true, "y_pred": y_pred}
        epoch_mae = MAE(pred_dict)
        epoch_r2 = R2(pred_dict)
        
        train_loss.append(epoch_loss)
        mae_train.append(epoch_mae)
        r2_train.append(epoch_r2)
        train_time = time.time() - train_start
        
        # 评估验证集（如果提供）- 每轮都评估以记录完整的训练轨迹
        eval_start = time.time()
        epoch_val_mae = None
        epoch_val_r2 = None
        current_epoch_num = epoch - start_epoch + 1  # 当前训练轮数（从1开始计数）
        
        if use_validation and val_loader is not None:
            try:
                model.eval()
                # 优化方案1: 在GPU上直接累积误差，减少CPU-GPU数据传输
                # 优化方案2: R²可以每N轮计算一次（可选，因为早停主要看MAE）
                compute_r2 = hyperparameters.get('compute_r2_every_epoch', True)  # 是否每轮都计算R²
                if not compute_r2:
                    compute_r2 = (current_epoch_num % 5 == 0 or current_epoch_num == 1 or (epoch + 1) == n_epochs)
                
                # 在GPU上累积MAE和R²所需的统计量，减少数据传输
                total_abs_error = torch.tensor(0.0, device=device, dtype=torch.float32)  # 在GPU上累积
                total_samples = 0
                val_y_true_gpu = []
                val_y_pred_gpu = []
                
                with torch.no_grad():
                    for batch_data in val_loader:
                        if len(batch_data) == 3:
                            batch_solvent, batch_solute, T = batch_data
                            T = T.to(device, non_blocking=True)  # 非阻塞传输
                            has_temperature = True
                        elif len(batch_data) == 2:
                            batch_solvent, batch_solute = batch_data
                            has_temperature = False
                        else:
                            raise ValueError(f"Unexpected batch size {len(batch_data)}")
                        
                        batch_solvent = batch_solvent.to(device, non_blocking=True)  # 非阻塞传输
                        batch_solute = batch_solute.to(device, non_blocking=True)  # 非阻塞传输
                        
                        with torch.autocast(device_type=device.type, enabled=(device.type == 'cuda')):
                            if has_temperature:
                                pred = model(batch_solvent, batch_solute, T)
                            else:
                                pred = model(batch_solvent, batch_solute)
                            prediction = pred.to(torch.float32)
                            real = batch_solvent.y.to(torch.float32).reshape(prediction.shape)
                        
                        # 在GPU上直接计算MAE（累积绝对误差和样本数，减少CPU-GPU数据传输）
                        abs_error = torch.abs(prediction - real)
                        total_abs_error += abs_error.sum()  # 保持在GPU上，累积tensor
                        total_samples += abs_error.numel()
                        
                        # 只在需要计算R²时才保存数据
                        if compute_r2:
                            val_y_true_gpu.append(real)
                            val_y_pred_gpu.append(prediction)
                
                # 计算MAE（在GPU上完成计算，最后一次性传输到CPU）
                if total_samples > 0:
                    epoch_val_mae = (total_abs_error / total_samples).item()  # 只传输最终结果
                else:
                    epoch_val_mae = 0.0
                
                # 计算R²（如果需要）
                if compute_r2 and len(val_y_true_gpu) > 0:
                    # 在GPU上拼接，然后一次性传输到CPU（使用非阻塞传输）
                    val_y_true_tensor = torch.cat(val_y_true_gpu, dim=0)
                    val_y_pred_tensor = torch.cat(val_y_pred_gpu, dim=0)
                    # 使用非阻塞传输，避免阻塞GPU计算
                    val_y_true = val_y_true_tensor.cpu().numpy()
                    val_y_pred = val_y_pred_tensor.cpu().numpy()
                    val_pred_dict = {"y_true": val_y_true, "y_pred": val_y_pred}
                    epoch_val_r2 = R2(val_pred_dict)
                else:
                    # 如果不需要计算R²，使用上一次的值或0
                    epoch_val_r2 = r2_valid[-1] if len(r2_valid) > 0 else 0.0
                
                # 清理GPU缓存（仅在需要时，避免频繁清理导致波动）
                if current_epoch_num % 10 == 0:  # 每10轮清理一次
                    torch.cuda.empty_cache()
                
                mae_valid.append(epoch_val_mae)
                r2_valid.append(epoch_val_r2)
            except Exception as e:
                print_report(f'⚠️ 警告: 验证集评估失败: {e}')
                import traceback
                traceback.print_exc()
                # 评估失败时，添加NaN以保持列表长度一致
                mae_valid.append(np.nan)
                r2_valid.append(np.nan)
            finally:
                # 切换回训练模式
                model.train()
        
        eval_time = time.time() - eval_start if use_validation and val_loader is not None else 0.0
        
        # 使用验证集MAE进行调度和早停（如果验证集可用），否则使用训练集MAE
        scheduler_start = time.time()
        metric_for_scheduler = epoch_val_mae if (use_validation and epoch_val_mae is not None) else epoch_mae
        scheduler.step(metric_for_scheduler)
        scheduler_time = time.time() - scheduler_start
        
        save_start = time.time()
        save_time = 0.0  # 初始化保存时间
        epoch_time = time.time() - epoch_start
        
        # 初始化found_better_model（在输出训练指标之前，避免未定义错误）
        found_better_model = False
        
        # 输出训练和验证集指标（始终显示训练集指标，如果有验证集则同时显示）
        # 添加详细时间统计，帮助识别时间瓶颈
        other_time = epoch_time - train_time - eval_time - scheduler_time - save_time
        if use_validation and epoch_val_mae is not None and epoch_val_r2 is not None:
            # 有验证集指标，同时显示训练集和验证集
            best_val_mae_str = f'{min(mae_valid):.6f}' if len(mae_valid) > 0 else 'N/A'
            # 详细时间统计（每10个epoch显示一次，或保存检查点时显示）
            if (epoch + 1) % 10 == 0 or found_better_model:
                print_report(f'Epoch {epoch+1}/{n_epochs} - Train MAE: {epoch_mae:.6f}, Train R²: {epoch_r2:.6f} | Valid MAE: {epoch_val_mae:.6f}, Valid R²: {epoch_val_r2:.6f} | Best Valid MAE: {best_val_mae_str}')
                print_report(f'  时间统计: 总={epoch_time:.2f}s (训练={train_time:.2f}s, 验证={eval_time:.2f}s, 调度={scheduler_time:.2f}s, 保存={save_time:.2f}s, 其他={other_time:.2f}s)')
            else:
                print_report(f'Epoch {epoch+1}/{n_epochs} - Train MAE: {epoch_mae:.6f}, Train R²: {epoch_r2:.6f} | Valid MAE: {epoch_val_mae:.6f}, Valid R²: {epoch_val_r2:.6f} | Best Valid MAE: {best_val_mae_str}, Time: {epoch_time:.2f}s')
        else:
            # 没有验证集指标，只显示训练集指标（明确标注为训练集）
            if (epoch + 1) % 10 == 0:
                print_report(f'Epoch {epoch+1}/{n_epochs} - Train MAE: {epoch_mae:.6f}, Train R²: {epoch_r2:.6f}')
                print_report(f'  时间统计: 总={epoch_time:.2f}s (训练={train_time:.2f}s, 调度={scheduler_time:.2f}s, 其他={other_time:.2f}s)')
            else:
                print_report(f'Epoch {epoch+1}/{n_epochs} - Train MAE: {epoch_mae:.6f}, Train R²: {epoch_r2:.6f}, Time: {epoch_time:.2f}s')
            if val_df is not None:
                if not use_validation:
                    print_report(f'⚠️ 警告: 验证集数据已提供但验证集评估未启用 (use_validation={use_validation}, val_loader={val_loader is not None})')
                # 若验证评估本轮未产生结果则静默跳过，避免重复警告
        
        # 使用验证集MAE选择最佳模型（如果验证集可用），否则使用训练集MAE
        # 每个epoch都会评估验证集（如果提供），因此早停基于每个epoch的验证集MAE
        current_mae = epoch_val_mae if (use_validation and epoch_val_mae is not None) else epoch_mae
        
        # 检查单次搜索终止条件（如果设置了相关参数）
        if use_validation and epoch_val_mae is not None:
            current_epoch_num = epoch - start_epoch + 1  # 当前训练轮数（从1开始计数）
            
            # 条件1: 检查起始MAE阈值（第1个epoch）
            if single_trial_start_mae_threshold is not None and current_epoch_num == 1 and epoch_val_mae > single_trial_start_mae_threshold:
                print_report(f'Early stopping triggered: 起始验证集MAE({epoch_val_mae:.6f}) > {single_trial_start_mae_threshold} (epoch {epoch+1})')
                break
            
            # 条件2: 检查训练指定轮数后的最佳MAE阈值
            # 在第single_trial_epochs_threshold轮时，检查前single_trial_epochs_threshold轮的最佳验证集MAE
            if single_trial_epochs_threshold is not None and single_trial_mae_after_epochs_threshold is not None:
                if current_epoch_num == single_trial_epochs_threshold:
                    # 在第100轮时，检查前100轮的最佳验证集MAE
                    if len(mae_valid) >= single_trial_epochs_threshold:
                        # 获取前single_trial_epochs_threshold轮的最佳MAE
                        best_val_mae_in_first_n_epochs = min(mae_valid[:single_trial_epochs_threshold])
                        if best_val_mae_in_first_n_epochs > single_trial_mae_after_epochs_threshold:
                            print_report(f'Early stopping triggered: 训练{single_trial_epochs_threshold}轮后，前{single_trial_epochs_threshold}轮中验证集最佳MAE({best_val_mae_in_first_n_epochs:.6f})仍 > {single_trial_mae_after_epochs_threshold} (epoch {epoch+1})')
                            break
        
        # 记录是否找到更好的模型（用于检查点保存判断）
        # 注意：found_better_model已在上面初始化，这里只需要更新
        if current_mae is not None:
            if current_mae < best_MAE:
                # 优化：使用轻量级复制替代深拷贝，避免阻塞训练
                # 使用 state_dict().copy() 创建浅拷贝，然后对每个张量进行克隆
                # 这比 deepcopy 快得多，且不会影响训练
                best_model = {k: v.clone() for k, v in model.state_dict().items()}
                best_MAE = current_mae
                epochs_no_improve = 0
                found_better_model = True  # 标记找到了更好的模型
            else:
                epochs_no_improve += 1
                if epochs_no_improve >= early_stopping_patience:
                    print_report(f'Early stopping triggered after {epoch+1} epochs (patience={early_stopping_patience} epochs)')
                    break

        # 检查点保存策略（更新版，确保每次试验都可以从最近断点恢复）
        # 1. **每个epoch都保存一次检查点** 到当前trial对应的目录下（覆盖写入同一个文件）
        # 2. 当找到更好模型时，检查点中的best_MAE和best_model_state_dict也会被更新
        # 3. 这样既能保证断点恢复能力，又兼容外部脚本从checkpoint中读取best_MAE的逻辑
        save_time = 0.0
        try:
            # 使用轻量级方式获取模型状态，避免重复调用state_dict()
            model_state = model.state_dict()
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': model_state,
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'scaler_state_dict': scaler.state_dict() if device.type == 'cuda' else None,
                # 只保存验证集历史（从这些信息可以恢复best_MAE等统计）
                'mae_valid': mae_valid.copy() if mae_valid else [],  # 验证集MAE历史
                'r2_valid': r2_valid.copy() if r2_valid else [],    # 验证集R²历史
                # 不保存训练集历史（从CSV文件读取，避免检查点文件过大）
                # 'mae_train': mae_train,      # 已保存在Training.csv
                # 'r2_train': r2_train,        # 已保存在Training.csv
                # 'train_loss': train_loss,     # 已保存在Training.csv
                'best_MAE': best_MAE,
                'best_model_state_dict': best_model,
                'epochs_no_improve': epochs_no_improve,
                'hyperparameters': hyperparameters,
                'random_seed': random_seed  # 保存随机种子以便后续查询
            }
            torch.save(checkpoint, checkpoint_path)
            save_time = time.time() - save_start
            # 根据是否找到更好模型输出不同提示信息
            if found_better_model:
                current_mae_str = f'{current_mae:.6f}' if current_mae is not None else 'nan'
                print_report(f'✓ 检查点已保存并更新最佳模型 (Epoch {epoch+1}, 当前MAE={current_mae_str}, Best MAE={best_MAE:.6f}, Save: {save_time:.2f}s)')
            else:
                # 不每个epoch都打印详细信息，以免日志过长：每10轮或最后一轮打印一次
                if (epoch + 1) % 10 == 0 or (epoch + 1) == n_epochs:
                    if current_mae is not None:
                        print_report(f'✓ 检查点已保存 (Epoch {epoch+1}, 当前MAE={current_mae:.6f}, Best MAE={best_MAE:.6f}, Save: {save_time:.2f}s)')
                    else:
                        print_report(f'✓ 检查点已保存 (Epoch {epoch+1}, Save: {save_time:.2f}s)')
        except Exception as e:
            print_report(f'警告: 保存检查点失败: {e}')
            save_time = time.time() - save_start
        
        # 定期暂停：每4小时暂停15分钟，给系统休息时间，避免长时间运行导致的问题
        current_time = time.time()
        elapsed_since_last_pause = current_time - last_pause_time
        pause_interval = 4 * 3600  # 4小时 = 4 * 3600秒
        pause_duration = 15 * 60   # 15分钟 = 15 * 60秒
        
        if elapsed_since_last_pause >= pause_interval:
            print_report('\n' + '='*80)
            print_report(f'⏸️  已连续运行 {elapsed_since_last_pause/3600:.2f} 小时，暂停15分钟让系统休息...')
            print_report(f'   当前epoch: {epoch+1}/{n_epochs}')
            print_report(f'   暂停开始时间: {time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())}')
            print_report('='*80)
            report.flush()  # 确保输出被写入文件
            
            # 暂停15分钟
            time.sleep(pause_duration)
            
            # 更新上次暂停时间
            last_pause_time = time.time()
            pause_end_time = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
            print_report('\n' + '='*80)
            print_report('▶️  暂停结束，继续训练')
            print_report(f'   暂停结束时间: {pause_end_time}')
            print_report('='*80 + '\n')
            report.flush()
        
        # 定期sleep：每10个epoch sleep 0.1秒，给系统其他进程让出时间
        # 这对于长时间训练很重要，可以避免长时间占用系统资源
        if (epoch + 1) % 10 == 0:
            time.sleep(0.1)

    print_report('-' * 30)
    if use_validation:
        # 使用验证集指标选择最佳epoch（基于验证集）
        # 排除NaN值，找到真正的最佳验证集MAE
        valid_mae_values = [m for m in mae_valid if not np.isnan(m)]
        if len(valid_mae_values) > 0:
            best_val_mae = min(valid_mae_values)
            best_epoch = mae_valid.index(best_val_mae) + 1
        else:
            # 如果没有有效的验证集MAE，使用训练集MAE
            best_epoch = mae_train.index(min(mae_train)) + 1
        print_report('Best Epoch     : ' + str(best_epoch))
        print_report('Training MAE   : ' + str(mae_train[best_epoch - 1]))
        print_report('Training R^2   : ' + str(r2_train[best_epoch - 1]))
        if best_epoch - 1 < len(mae_valid) and not np.isnan(mae_valid[best_epoch - 1]):
            print_report('Validation MAE : ' + str(mae_valid[best_epoch - 1]))
            print_report('Validation R^2 : ' + str(r2_valid[best_epoch - 1]))
        else:
            print_report('Validation MAE : N/A')
            print_report('Validation R^2 : N/A')
        print_report('Training Loss  : ' + str(train_loss[best_epoch - 1]))
    else:
        # 使用训练集指标选择最佳epoch（没有验证集时）
        best_epoch = mae_train.index(min(mae_train)) + 1
        print_report('Best Epoch     : ' + str(best_epoch))
        print_report('Training MAE   : ' + str(mae_train[best_epoch - 1]))
        print_report('Training R^2   : ' + str(r2_train[best_epoch - 1]))
        print_report('Training Loss  : ' + str(train_loss[best_epoch - 1]))

    # Save training trajectory
    df_model_training = pd.DataFrame(train_loss, columns=['Train_loss'])
    df_model_training['MAE_Train'] = mae_train
    df_model_training['R2_Train'] = r2_train
    if use_validation:
        # 检查验证集指标长度是否与训练集指标长度匹配
        train_len = len(mae_train)
        val_len = len(mae_valid)
        if val_len != train_len:
            # 静默用 NaN 填充，避免警告输出
            mae_valid = (mae_valid + [np.nan] * train_len)[:train_len]
            r2_valid = (r2_valid + [np.nan] * train_len)[:train_len]
        df_model_training['MAE_Valid'] = mae_valid
        df_model_training['R2_Valid'] = r2_valid
        save_train_traj(path, df_model_training, valid=True)
    else:
        # 没有有效的验证集轨迹时，只保存训练集轨迹
        save_train_traj(path, df_model_training, valid=False)

    # Save best model
    model_name_basename = model_name.split('/')[-1] if '/' in model_name else model_name
    if best_model is not None:
        # 保存最佳模型权重和元数据（包括随机种子）
        best_model_dict = {
            'model_state_dict': best_model,
            'random_seed': random_seed,
            'hyperparameters': hyperparameters,
            'best_MAE': best_MAE,
            'best_epoch': mae_train.index(min(mae_train)) + 1
        }
        torch.save(best_model_dict, os.path.join(path, model_name_basename + '_best.pth'))
    else:
        # 如果没有best_model，保存当前模型状态和元数据
        best_model_dict = {
            'model_state_dict': model.state_dict(),
            'random_seed': random_seed,
            'hyperparameters': hyperparameters,
            'best_MAE': best_MAE,
            'best_epoch': len(mae_train)
        }
        torch.save(best_model_dict, os.path.join(path, model_name_basename + '_best.pth'))

    end = time.time()

    print_report('\nTraining time (min): ' + str((end - start) / 60))
    report.close()

if __name__ == '__main__':
    hyperparameters_dict = {'hidden_dim'  : 38,
                            'lr'          : 0.0002532501358651798,
                            'n_epochs'    : 400,
                            'batch_size'  : 64,
                            'early_stopping_patience': 10
                            }
    df = pd.read_csv('D:\\化工预测\\论文复现结果\\GH-GEAT\\data\\processed\\new_dataset\\train_dataset\\v2\\molecule_train.csv')
    train_GNNGH_T(df, 'GHGEAT_wo_1117', hyperparameters_dict)









































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































